# ğŸš€ Parallel Web Scraper & Keyword Analyzer

## ğŸ“Œ Project Overview
Parallel Web Scraper & Keyword Analyzer is a high-performance Go application that scrapes multiple websites concurrently, analyzes the most frequent words, and stores the results in a MongoDB database with Redis caching.

## âš¡ Features
- **Concurrent Web Scraping**: Uses Go's goroutines and channels for efficient parallel scraping.
- **Redis Caching**: Avoids unnecessary HTTP requests by caching previously scraped pages.
- **Keyword Analysis**: Extracts and counts the most frequently used words in the scraped content.
- **MongoDB Storage**: Persists results for future analysis and retrieval.
- **API Support**: Easily extendable with a REST API to fetch stored data.

## ğŸ“‚ Project Structure
```
/ParallelScraper
â”‚â”€â”€ main.go                    # Entry point of the application
â”‚â”€â”€ /scraper
â”‚   â”œâ”€â”€ scraper.go              # Handles web scraping logic
â”‚â”€â”€ /analyzer
â”‚   â”œâ”€â”€ analyzer.go             # Processes text and analyzes keywords
â”‚â”€â”€ /database
â”‚   â”œâ”€â”€ mongo.go                # MongoDB connection & operations
â”‚   â”œâ”€â”€ redis.go                # Redis caching logic
â”‚â”€â”€ go.mod                      # Go module dependencies
â”‚â”€â”€ go.sum                      # Checksums for dependencies
â”‚â”€â”€ README.md                   # Project documentation
```

## ğŸš€ Getting Started
### 1ï¸âƒ£ Prerequisites
Ensure you have the following installed:
- Go 1.18+
- MongoDB
- Redis

### 2ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/yourusername/ParallelScraper.git
cd ParallelScraper
```

### 3ï¸âƒ£ Install Dependencies
```sh
go mod tidy
```

### 4ï¸âƒ£ Configure Environment Variables
Create a `.env` file with:
```env
MONGO_URI=mongodb://localhost:27017
REDIS_ADDR=localhost:6379
```

### 5ï¸âƒ£ Run the Application
```sh
go run main.go
```

## ğŸ“Š How It Works
1. User provides multiple URLs.
2. The scraper fetches web pages concurrently using goroutines and channels.
3. Redis checks for cached content before sending requests.
4. The analyzer processes and identifies frequently used words.
5. Data is stored in MongoDB for future retrieval.

## ğŸ› ï¸ Technologies Used
- **Golang** (Concurrency, Goroutines, Channels)
- **Colly** (Web Scraping)
- **MongoDB** (Data Storage)
- **Redis** (Caching)
- **Gin** (Optional: API Framework)

## ğŸ¤ Contributing
Feel free to fork this repository, submit issues, or create pull requests!

## ğŸ“œ License
This project is licensed under the MIT License.

---

Happy coding! ğŸš€
